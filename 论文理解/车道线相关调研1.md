# Towards End-to-End Lane Detection: an Instance Segmentation Approach（2018.2）

## 数据集

- tusimple
- 数据集介绍：
  - 主要是高速路上车道数据；
  - 训练集中有3626个flips，每个flips包括20帧图片，最后一帧有标注信息；
  - 原始图片大小：1280X720；
  - 车道线标注格式（json格式）；
  - ![](.\images\tusimpleData.PNG)
  - h_sample:将图像在高度上等距离划分若干点；
  - lanes:列表个数表示该图片中包含车道线的个数，对于每一个列表，记录的是该车道线所处位置的宽度位置；
  - 标注的信息无法区分双实线、白线、黄线等具体类型的车道线；所有车道线统一对待；

## 适用类型和环境场景

- 类型
  - 直道（可以）
  - 弯道（可以）
  - 上坡、下坡（可以）
  - 低速、高速（得看模型最后的运行速度）
  - 实线/虚线/实现+虚线/双实线（不可以）
- 环境场景
  - 白天（可以）
  - 晚上（待查）
  - 雨天（待查）
  - 强光（待查）
  - 雪天（待查）
  - 雾天（待查）



## 算法

![](.\images\Lanet1.png)





- 将车道检测问题转化为实例分割问题，每个车道线形成独立的实例；
- 可处理不固定车道线和车道变化；
- 在拟合车道线时，提出H-Net，用于学习透视变换矩阵，较之前固定且预先定义的变换矩阵相比，提高了道路平面变化情况下的车道线拟合的鲁棒性。
- 模型输入图片大小：512X256

![](.\images\Lanet.png)



### binary segmentation branch

- 用于训练输出得到一个二值化的分割图，白色代表车道线，黑色代表背景
- loss：交叉熵损失函数
- 类别不平衡： apply bounded inverse class weighting
- 构建ground-truth分割图时，将每个车道线的对应像素连成线；好处是车道线被遮挡了或车道线消失，网络仍能预测车道位置。



### instance embeding branch

- 目的：区分binary segmentation得到车道线，每条车道具体包含哪些像素点;

- **pixel embedding**: mapping each pixel to a point in n-d feature space

- 具体做法参考了论文：Semantic Instance Segmentation for Autonomous Driving和Semantic Instance Segmentation with a Discriminative Loss Function，提出的针对实例分割提出的LossFunction

  - 实例分割任务中，softmax loss的缺陷：

    - 应用 `softmax loss` 的网络的最后输出层的 `channel` 数等于类别数，因为图像中的实例数目不定，所以网络最后层的结构无法确定。

    - 如果网络每个像素的预测输出和 `ground truth`的`id-label`不一致 ，如下图：

    - ![](D:/myLaneDetection/papers/%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/images/image3.png)

      `softmax loss` 会惩罚这种 **预测错误**。 但是: 这种预测结果其实是对的，只要不同实例之间的 `id-label` 不同就可以，即 `instance id label` 满足 `permutation-invariant`( “**置换不变性**”

      )的性质。

  - ![](D:/myLaneDetection/papers/%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/images/Loss.PNG)

  - 用新提出的 `loss function` 对网络进行训练。优化目标是： 网络将图像每个像素投影到 `n-d`特征空间（`n` 是个随数据集变化而变化的超参），使得同属于一个实例的像素尽量靠近，形成一个 `cluster`, 每一个实例对应一个 `cluster`, 不同 `cluster`则尽量远离。

  - ![](D:/myLaneDetection/papers/%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/images/Loss1.PNG)

  - 终止聚类的条件是：车道聚类（即各车道线间间距）中心间距离>δd,每个类（每条车道线）中包含的车道线像素离该车道线距离<δv。

    两个分支的loss权重相同。

### 最后聚类过程：

- 先利用binary segmentation branch得到的结果对instance embeding branch得到的embeding做掩码，然后再聚类。

- 设置 δd > 6δv为迭代终止条件，使上述的loss做迭代。（6为超参数）

  ​	

### CURVE FITTING USING H-NET

![](D:/myLaneDetection/papers/%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/images/space_chansform.PNG)

流行的拟合模型有三次多项式，样条曲线，回旋曲线。为了提高拟合质量且保持计算效率，通常将图像转到鸟瞰图后做拟合。最后再逆变换到原图即可。但有个问题是：这个透视变换矩阵会受地面线影响（如上坡）。本文在做曲线拟合前先训练一个网络用于生成透视变换矩阵系数以解决道路平面变动(上下坡)的影响。

![](D:/myLaneDetection/papers/%E8%AE%BA%E6%96%87%E7%90%86%E8%A7%A3/images/H-Net.PNG)



转换矩阵6个自由度：（另外三个固定，是为了保证水平线在转换后的空间仍保持水平，增加了限制条件）

![](./images/H_Net_transform.PNG)



### 评价标准

在tusimple数据集上以准确率为评价标准。(预测准确的点/ground truth中的点)

准确率的计算：

![](.\images\ACC.PNG)







## 结果

- ![](./images/RANK.PNG)
- 在tusimple数据集上准确率为96.4%。
- 训练模型的硬件：a NVIDIA 1080Ti
- 速度：52fps



## 优点与改进

- 可以处理车道变化的情况，车道数量可以有变化；

- 在拟合车道线时，提出H-Net，用于学习透视变换矩阵，较之前固定且预先定义的变换矩阵相比，提高了道路平面变化情况下的车道线拟合的鲁棒性。

  



# Spatial As Deep: Spatial CNN for Traffic Scene Understanding

